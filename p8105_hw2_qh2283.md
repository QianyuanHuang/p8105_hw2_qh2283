p8105_hw2_qh2283
================
2023-10-01

Q1

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
# 1. Clean the data in pols-month.csv
pols <- read.csv("/Users/hoc/Desktop/p8105_hw2_qh2283/fivethirtyeight_datasets/pols-month.csv")

pols_clean <- pols %>%
  # separate 'mon' into 'year', 'month', and 'day'
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  # convert month number to month name
  mutate(month = month(as.integer(month), label = TRUE)) %>%
  # create 'president' variable
  mutate(president = ifelse(!is.na(prez_dem), "dem", "gop")) %>%
  # remove 'prez_dem' and 'prez_gop'
  select(-prez_dem, -prez_gop) %>%
  # remove 'day' variable
  select(-day)
```

``` r
# 2. Clean the data in snp.csv
snp <- read.csv("/Users/hoc/Desktop/p8105_hw2_qh2283/fivethirtyeight_datasets/snp.csv")
snp_clean <- snp %>%
  # assuming the date column in snp.csv is named 'date'
  separate(date, into = c("year", "month"), sep = "-") %>%
  mutate(month = month(as.integer(month), label = TRUE)) %>%
  arrange(year, month) %>%
  select(year, month, everything())
```

    ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 787 rows [1, 2, 3, 4, 5,
    ## 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

``` r
# 3. Tidy the unemployment data
unemployment <- read.csv("/Users/hoc/Desktop/p8105_hw2_qh2283/fivethirtyeight_datasets/unemployment.csv")

unemployment_long <- unemployment %>%
  # convert from wide to long format with all columns
  gather(key = "date", value = "unemployment_rate") %>%
  # separate 'date' into 'year' and 'month'
  separate(date, into = c("year", "month"), sep = "-") %>%
  # convert month names to month labels
  mutate(month = month(as.integer(month), label = TRUE))
```

    ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 884 rows [1, 2, 3, 4, 5,
    ## 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

``` r
# Join the datasets
merged_data <- pols_clean %>%
  left_join(snp_clean, by = c("year", "month")) %>%
  left_join(unemployment_long, by = c("year", "month"))
```

Q2

``` r
library(tidyverse)
library(readxl)

#Import and clean Mr.Trash Wheel data
mr_trash_wheel <- 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N586") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))|>
  mutate(homes_powered = (weight_tons * 500) %/% 30)

#Import and clean Professor Trash Wheel data
prof_trash_wheel <- 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M108") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))|>
  mutate(homes_powered = (weight_tons * 500) %/% 30)

#Import and clean Gwynnda Trash Wheel data
gwy_trash_wheel <- 
  read_excel("202309 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L157") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))|>
  mutate(homes_powered = (weight_tons * 500) %/% 30)

#Add a new variable 
mr_trash_wheel <- mr_trash_wheel %>% mutate(wheel_name = "Mr. Trash Wheel")

prof_trash_wheel <- prof_trash_wheel %>% mutate(wheel_name = "Professor Trash Wheel")

gwy_trash_wheel <- gwy_trash_wheel %>% mutate(wheel_name = "Gwynnda Trash Wheel")

#Convert "year" to numeric
mr_trash_wheel$year <- as.numeric(mr_trash_wheel$year)
prof_trash_wheel$year <- as.numeric(prof_trash_wheel$year)
gwy_trash_wheel$year <- as.numeric(gwy_trash_wheel$year)

#Combine all datasets
trash_wheel_collection <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwy_trash_wheel)
str(trash_wheel_collection)
```

    ## tibble [845 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:845] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:845] "May" "May" "May" "May" ...
    ##  $ year              : num [1:845] 2014 2014 2014 2014 2014 ...
    ##  $ date              : POSIXct[1:845], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:845] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:845] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:845] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:845] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:845] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:845] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ plastic_bags      : num [1:845] 584 496 1080 896 368 ...
    ##  $ wrappers          : num [1:845] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:845] 7.2 5.2 6 6 7.2 5.2 3.2 6.4 5.6 7.2 ...
    ##  $ homes_powered     : num [1:845] 71 45 57 51 67 45 31 61 42 62 ...
    ##  $ wheel_name        : chr [1:845] "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" "Mr. Trash Wheel" ...

Discription  
The `trash_wheel_collection` dataset amalgamates data from three
distinct sources: `mr_trash_wheel`, `prof_trash_wheel`, and
`gwy_trash_wheel`. It encompasses 845 records and 15 attributes. Within
this dataset, specific columns provide information on collection dates
(`date`), total trash weight (`weight_tons`), different trash categories
like `plastic_bags`, and a computed variable, `homes_powered`. As per
the dataset, Professor Trash Wheel was responsible for collecting 216.26
tons of waste. Furthermore, in July 2021, Gwynnda gathered 1.63^{4}
cigarette ends.

Q3

``` r
library(tidyverse)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

``` r
library(lubridate)

# Import and clean 
baseline <- 
  read.csv("data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(
      #convert "sex" and "apoe4" to string
      sex = recode(sex, "1" = "male", "0" = "female"),
      apoe4 = recode(apoe4, "1" = "carrier", "0" = "non-carrier")
  ) |>
  rename("study_id" = "id")
  
# Remove participants who do not meet the criteria 
baseline2 <- filter(baseline, is.na(age_at_onset) | age_at_onset == "." | current_age < age_at_onset)

# Filter the number of participants who developed MCI
mci_developed <- filter(baseline2, !is.na(age_at_onset) & age_at_onset != ".")

w_a_c <- sum(baseline$sex == "female" & baseline$apoe4 == "carrier")
total_women <- sum(baseline$sex == "female")
```

Discription  
After importing the data, we transform the `sex` and `apoe4` variables
to render them more interpretably. The initial baseline dataset contains
483 entries. Yet, from these, only 479 individuals satisfied the given
criteria, as reflected by the record count in the `baseline2` dataset.
Additionally, 93 of the participants were diagnosed with MCI. The mean
age of participants at baseline is 65.03. Within the research, the
percentage of female carriers is 29.86%.

``` r
# Import and clean the biomarker values dataset
amyloid <- 
  read.csv("data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names()
amyloid2 <- pivot_longer(amyloid, baseline:time_8, names_to = "time", values_to = "years")

# Combine datasets
combined_mci <- merge(baseline2, amyloid2, by = "study_id")

# Check participants in one of the datasets
only_baseline <- setdiff(baseline2$study_id, amyloid2$study_id)
only_amyloid <- setdiff(amyloid2$study_id, baseline2$study_id)

# Exporting to CSV file
write.csv(combined_mci, "data_mci/combined_mci.csv", row.names = FALSE)
```

In the baseline dataset, there are 8 participants. In the amyloid
dataset, there are 16 participants. When combined, the new dataset
contains 2355 records with 8 different kinds of data.
